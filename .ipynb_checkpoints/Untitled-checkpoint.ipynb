{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-71304e754806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import os,time,cv2, sys, math\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import argparse\n",
    "import random\n",
    "import os, sys\n",
    "\n",
    "import helpers \n",
    "import utils \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"models\")\n",
    "from FC_DenseNet_Tiramisu import build_fc_densenet\n",
    "from Encoder_Decoder import build_encoder_decoder\n",
    "from RefineNet import build_refinenet\n",
    "from FRRN import build_frrn\n",
    "from MobileUNet import build_mobile_unet\n",
    "from PSPNet import build_pspnet\n",
    "from GCN import build_gcn\n",
    "from HF_FCN import build_hf_fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--num_epochs', type=int, default=300, help='Number of epochs to train for')\n",
    "parser.add_argument('--is_training', type=str2bool, default=True, help='Whether we are training or testing')\n",
    "parser.add_argument('--continue_training', type=str2bool, default=False, help='Whether to continue training from a checkpoint')\n",
    "parser.add_argument('--dataset', type=str, default=\"CamVid\", help='Dataset you are using.')\n",
    "parser.add_argument('--crop_height', type=int, default=360, help='Height of input image to network')\n",
    "parser.add_argument('--crop_width', type=int, default=480, help='Width of input image to network')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='Width of input image to network')\n",
    "parser.add_argument('--num_val_images', type=int, default=10, help='The number of images to used for validations')\n",
    "parser.add_argument('--h_flip', type=str2bool, default=False, help='Whether to randomly flip the image horizontally for data augmentation')\n",
    "parser.add_argument('--v_flip', type=str2bool, default=False, help='Whether to randomly flip the image vertically for data augmentation')\n",
    "parser.add_argument('--brightness', type=float, default=None, help='Whether to randomly change the image brightness for data augmentation')\n",
    "parser.add_argument('--rotation', type=float, default=None, help='Whether to randomly rotate the image for data augmentation')\n",
    "parser.add_argument('--zoom', type=float, default=None, help='Whether to randomly zoom in for data augmentation')\n",
    "parser.add_argument('--model', type=str, default=\"FC-DenseNet103\", help='The model you are using. Currently supports: FC-DenseNet56, FC-DenseNet67, FC-DenseNet103, FC-DenseNet158, FC-DenseNet232, HF-FCN, Encoder-Decoder, Encoder-Decoder-Skip, RefineNet-Res50, RefineNet-Res101, RefineNet-Res152, FRRN-A, FRRN-B, MobileUNet, MobileUNet-Skip, PSPNet-Res50, PSPNet-Res101, PSPNet-Res152, GCN-Res50, GCN-Res101, GCN-Res152, custom')\n",
    "parser.add_argument('--exp_id', type=int, default=1, help='Number of experiments')\n",
    "parser.add_argument('--gpu_ids', type=str, default=0, help='List of GPU device id')\n",
    "parser.add_argument('--is_BC', type=str2bool, default=False, help='whegher to use balanced weight')\n",
    "parser.add_argument('--is_balanced_weight', type=str2bool, default=False, help='whegher to use balanced weight')\n",
    "parser.add_argument('--is_edge_weight', type=str2bool, default=False, help='whegher to use balanced weight')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "# Get a list of the training, validation, and testing file paths\n",
    "def prepare_data(dataset_dir=args.dataset):\n",
    "    train_input_names=[]\n",
    "    train_output_names=[]\n",
    "    train_output_weight_names=[]\n",
    "    val_input_names=[]\n",
    "    val_output_names=[]\n",
    "    test_input_names=[]\n",
    "    test_output_names=[]\n",
    "    for file in os.listdir(dataset_dir + \"/train\"):\n",
    "        cwd = os.getcwd()\n",
    "        train_input_names.append(cwd + \"/\" + dataset_dir + \"/train/\" + file)\n",
    "    for file in os.listdir(dataset_dir + \"/train_labels\"):\n",
    "        cwd = os.getcwd()\n",
    "        train_output_names.append(cwd + \"/\" + dataset_dir + \"/train_labels/\" + file)\n",
    "    if args.is_edge_weight:\n",
    "        for file in os.listdir(dataset_dir + \"/train_labels_weights\"):\n",
    "            cwd = os.getcwd()\n",
    "            train_output_weight_names.append(cwd + \"/\" + dataset_dir + \"/train_labels_weights/\" + file)\n",
    "    for file in os.listdir(dataset_dir + \"/val\"):\n",
    "        cwd = os.getcwd()\n",
    "        val_input_names.append(cwd + \"/\" + dataset_dir + \"/val/\" + file)\n",
    "    for file in os.listdir(dataset_dir + \"/val_labels\"):\n",
    "        cwd = os.getcwd()\n",
    "        val_output_names.append(cwd + \"/\" + dataset_dir + \"/val_labels/\" + file)\n",
    "    for file in os.listdir(dataset_dir + \"/test\"):\n",
    "        cwd = os.getcwd()\n",
    "        test_input_names.append(cwd + \"/\" + dataset_dir + \"/test/\" + file)\n",
    "    for file in os.listdir(dataset_dir + \"/test_labels\"):\n",
    "        cwd = os.getcwd()\n",
    "        test_output_names.append(cwd + \"/\" + dataset_dir + \"/test_labels/\" + file)\n",
    "    return train_input_names,train_output_names, train_output_weight_names, val_input_names, val_output_names, test_input_names, test_output_names\n",
    "\n",
    "def average_losses(loss):\n",
    "    tf.add_to_collection('losses', loss)\n",
    "    # Assemble all of the losses for the current tower only.\n",
    "    losses = tf.get_collection('losses')\n",
    "    # Calculate the total loss for the current tower.\n",
    "    regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    total_loss = tf.add_n(losses + regularization_losses, name='total_loss')\n",
    "    # Compute the moving average of all individual losses and the total loss.\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "    with tf.control_dependencies([loss_averages_op]):\n",
    "        total_loss = tf.identity(total_loss)\n",
    "    return total_loss\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "    Note that this function provides a synchronization point across all towers.\n",
    "    Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "    is over individual gradients. The inner list is over the gradient\n",
    "    calculation for each tower.\n",
    "    Returns:\n",
    "    List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "    across all towers.\n",
    "    \"\"\"\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads\n",
    "\n",
    "def feed_all_gpu(inp_dict, models, payload_per_gpu, batch_x, batch_y, batch_w):\n",
    "    for i in range(len(models)):\n",
    "        if args.is_edge_weight:\n",
    "            input, output, weight, _, _, _ = models[i]\n",
    "        else:\n",
    "            input, output, _, _, _ = models[i]\n",
    "        start_pos = i * payload_per_gpu\n",
    "        stop_pos = (i + 1) * payload_per_gpu\n",
    "        inp_dict[input] = batch_x[start_pos:stop_pos]\n",
    "        inp_dict[output] = batch_y[start_pos:stop_pos]\n",
    "        if ((args.is_edge_weight) and (batch_w is not None)):\n",
    "            inp_dict[weight] = batch_w[start_pos:stop_pos]\n",
    "    return inp_dict\n",
    "\n",
    "# Check if model is available\n",
    "AVAILABLE_MODELS = [\"FC-DenseNet56\", \"FC-DenseNet67\", \"FC-DenseNet103\", \"FC-DenseNet158\", \"FC-DenseNet232\", \n",
    "                    \"Encoder-Decoder\", \"Encoder-Decoder-Skip\", \n",
    "                    \"RefineNet-Res101\", \"RefineNet-Res152\", \"HF-FCN\", \"custom\"]\n",
    "if args.model not in AVAILABLE_MODELS:\n",
    "    print(\"Error: given model is not available. Try these:\")\n",
    "    print(AVAILABLE_MODELS)\n",
    "    print(\"Now exiting ...\")\n",
    "    sys.exit()\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading the data ...\")\n",
    "train_input_names, train_output_names, train_output_weight_names, val_input_names, val_output_names, test_input_names, test_output_names = prepare_data()\n",
    "\n",
    "print(len(train_input_names),len(train_output_names),len(train_output_weight_names))\n",
    "print(len(val_input_names),len(val_output_names),len(test_input_names),len(test_output_names))\n",
    "\n",
    "class_names_list = helpers.get_class_list(os.path.join(args.dataset, \"class_list.txt\"))\n",
    "class_names_string = \"\"\n",
    "for class_name in class_names_list:\n",
    "    if not class_name == class_names_list[-1]:\n",
    "        class_names_string = class_names_string + class_name + \", \"\n",
    "    else:\n",
    "        class_names_string = class_names_string + class_name\n",
    "\n",
    "num_classes = len(class_names_list)\n",
    "\n",
    "if args.is_balanced_weight:\n",
    "    b_weight = utils.median_frequency_balancing(args.dataset + \"/train_labels/\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = None\n",
    "init_fn = None\n",
    "print(\"Preparing the model ...\")\n",
    "opt = tf.train.RMSPropOptimizer(learning_rate=0.001, decay=0.995)#.minimize(loss, var_list=[var for var in tf.trainable_variables()])\n",
    "gpu_ids = args.gpu_ids.split(',')\n",
    "print('build model...')\n",
    "print('build model on gpu tower...')\n",
    "models = []\n",
    "for gpu_id in gpu_ids:\n",
    "    gpu_id = int(gpu_id)\n",
    "    with tf.device('/gpu:%d' % gpu_id):\n",
    "        print('using tower:%d...'% gpu_id)\n",
    "        with tf.name_scope('tower_%d' % gpu_id):\n",
    "            with tf.variable_scope('gpu_variables', reuse=gpu_id>0):\n",
    "                input = tf.placeholder(tf.float32,shape=[None,None,None,3])\n",
    "                output = tf.placeholder(tf.float32,shape=[None,None,None,num_classes])\n",
    "                if args.is_balanced_weight or args.is_edge_weight:\n",
    "                    weight = tf.placeholder(tf.float32,shape=[None,None,None])\n",
    "\n",
    "                if args.model == \"FC-DenseNet56\" or args.model == \"FC-DenseNet67\" or args.model == \"FC-DenseNet103\" or args.model == \"FC-DenseNet158\" or args.model == \"FC-DenseNet232\":\n",
    "                    if args.is_BC:\n",
    "                        network = build_fc_densenet(input, preset_model = args.model, num_classes=num_classes, is_bottneck=1, compression_rate=0.5)\n",
    "                    else:\n",
    "                        network = build_fc_densenet(input, preset_model = args.model, num_classes=num_classes, is_bottneck=False, compression_rate=1)\n",
    "                elif args.model == \"RefineNet-Res50\" or args.model == \"RefineNet-Res101\" or args.model == \"RefineNet-Res152\":\n",
    "                    # RefineNet requires pre-trained ResNet weights\n",
    "                    network, init_fn = build_refinenet(input, preset_model = args.model, num_classes=num_classes)\n",
    "                elif args.model == \"FRRN-A\" or args.model == \"FRRN-B\":\n",
    "                    network = build_frrn(input, preset_model = args.model, num_classes=num_classes)\n",
    "                elif args.model == \"Encoder-Decoder\" or args.model == \"Encoder-Decoder-Skip\":\n",
    "                    network = build_encoder_decoder(input, preset_model = args.model, num_classes=num_classes)\n",
    "                elif args.model == \"MobileUNet\" or args.model == \"MobileUNet-Skip\":\n",
    "                    network = build_mobile_unet(input, preset_model = args.model, num_classes=num_classes)\n",
    "                elif args.model == \"PSPNet-Res50\" or args.model == \"PSPNet-Res101\" or args.model == \"PSPNet-Res152\":\n",
    "                    # Image size is required for PSPNet\n",
    "                    # PSPNet requires pre-trained ResNet weights\n",
    "                    network, init_fn = build_pspnet(input, label_size=[args.crop_height, args.crop_width], preset_model = args.model, num_classes=num_classes)\n",
    "                elif args.model == \"GCN-Res50\" or args.model == \"GCN-Res101\" or args.model == \"GCN-Res152\":\n",
    "                    network, init_fn = build_gcn(input, preset_model = args.model, num_classes=num_classes)\n",
    "                elif args.model == \"custom\":\n",
    "                    network = build_custom(input, num_classes) \n",
    "                else:\n",
    "                    raise ValueError(\"Error: the model %d is not available. Try checking which models are available using the command python main.py --help\")\n",
    "\n",
    "                # Compute your (unweighted) softmax cross entropy loss\n",
    "                if args.is_balanced_weight:\n",
    "                    pixel_weight = b_weight*tf.argmax(input=output,dimension=3)+tf.argmin(input=output,dimension=3)\n",
    "                    pixel_weight = tf.cast(pixel_weight, tf.float32)\n",
    "                    loss = tf.reduce_mean(tf.multiply(pixel_weight*tf.nn.softmax_cross_entropy_with_logits(logits=network, labels=output)))\n",
    "                elif args.is_edge_weight:\n",
    "                    loss = tf.reduce_mean(tf.multiply(weight,tf.nn.softmax_cross_entropy_with_logits(logits=network, labels=output)))\n",
    "                else:\n",
    "                    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network, labels=output))\n",
    "                    \n",
    "                grads = opt.compute_gradients(loss)\n",
    "                if args.is_edge_weight:\n",
    "                    models.append((input,output,weight,network,loss,grads))\n",
    "                else:\n",
    "                    models.append((input,output,network,loss,grads))\n",
    "\n",
    "print('build model on gpu tower done.')\n",
    "print('reduce model on cpu...')\n",
    "if args.is_edge_weight:\n",
    "    _, _, _, tower_preds, tower_losses, tower_grads = zip(*models)\n",
    "else:\n",
    "    _, _, tower_preds, tower_losses, tower_grads = zip(*models)\n",
    "aver_loss_op = tf.reduce_mean(tower_losses)\n",
    "apply_gradient_op = opt.apply_gradients(average_gradients(tower_grads))\n",
    "all_pred = tf.reshape(tf.stack(tower_preds, 0), [-1, args.crop_width, args.crop_height, num_classes])\n",
    "print('reduce model on cpu done.')\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "saver=tf.train.Saver(max_to_keep=1000)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "utils.count_params()\n",
    "\n",
    "# If a pre-trained ResNet is required, load the weights.\n",
    "# This must be done AFTER the variables are initialized with sess.run(tf.global_variables_initializer())\n",
    "if init_fn is not None:\n",
    "    init_fn(sess)\n",
    "\n",
    "model_checkpoint_name = \"checkpoints_#%d/latest_model.ckpt\" % args.exp_id #_\" + args.model + \"_\" + args.dataset + \"\n",
    "if args.continue_training or not args.is_training:\n",
    "    print('Loaded latest model checkpoint')\n",
    "    saver.restore(sess, model_checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_scores_per_epoch = []\n",
    "\n",
    "if args.is_training:\n",
    "    f = open('loss_#%d.txt' % (args.exp_id),'w')\n",
    "    print(\"***** Begin training *****\")\n",
    "    print(\"exp_id -->\", args.exp_id)\n",
    "    print('loss wirte to loss_#%d.txt' % (args.exp_id))\n",
    "    print(\"gpu_ids>\", args.gpu_ids)\n",
    "    print(\"Dataset -->\", args.dataset)\n",
    "    print(\"Model -->\", args.model)\n",
    "    print(\"Crop Height -->\", args.crop_height)\n",
    "    print(\"Crop Width -->\", args.crop_width)\n",
    "    print(\"Num Epochs -->\", args.num_epochs)\n",
    "    print(\"Batch Size -->\", args.batch_size)\n",
    "    print(\"is_BC -->\", args.is_BC)\n",
    "    print(\"is_balanced_weight -->\", args.is_balanced_weight)\n",
    "    print(\"is_edge_weight -->\", args.is_edge_weight)\n",
    "    \n",
    "    print(\"Data Augmentation:\")\n",
    "    print(\"\\tVertical Flip -->\", args.v_flip)\n",
    "    print(\"\\tHorizontal Flip -->\", args.h_flip)\n",
    "    print(\"\\tBrightness Alteration -->\", args.brightness)\n",
    "    print(\"\\tRotation -->\", args.rotation)\n",
    "    print(\"\\tZooming -->\", args.zoom)\n",
    "    print(\"\")\n",
    "\n",
    "    avg_loss_per_epoch = []\n",
    "\n",
    "    # Which validation images doe we want\n",
    "    val_indices = []\n",
    "    num_vals = min(args.num_val_images, len(val_input_names))\n",
    "    for i in range(num_vals):\n",
    "        ind = random.randint(0, len(val_input_names) - 1)\n",
    "        val_indices.append(ind)\n",
    "\n",
    "    # Do the training here\n",
    "    for epoch in range(0, args.num_epochs):\n",
    "\n",
    "        current_losses = []\n",
    "\n",
    "        cnt=0\n",
    "        id_list = np.random.permutation(len(train_input_names))\n",
    "        num_iters = int(np.floor(len(id_list) / args.batch_size))\n",
    "        payload_per_gpu = args.batch_size/len(gpu_ids)\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            st=time.time()\n",
    "            \n",
    "            input_image_batch = []\n",
    "            output_image_batch = []\n",
    "            pixel_weight_batch = [] \n",
    "\n",
    "            inp_dict = {}\n",
    "\n",
    "            # Collect a batch of images\n",
    "            for j in range(args.batch_size):\n",
    "                index = i*args.batch_size + j\n",
    "                id = id_list[index]\n",
    "                input_image = cv2.cvtColor(cv2.imread(train_input_names[id],-1), cv2.COLOR_BGR2RGB)\n",
    "                output_image = cv2.imread(train_output_names[id],-1)\n",
    "                if args.is_edge_weight:\n",
    "                    pixel_weight = cv2.imread(train_output_weight_names[id],-1)\n",
    "                    # Data augmentation\n",
    "                    input_image, output_image, pixel_weight = utils.random_crop(input_image, output_image, pixel_weight, args.crop_height, args.crop_width)\n",
    "                else:\n",
    "                    input_image, output_image = utils.random_crop(input_image, output_image, None, args.crop_height, args.crop_width)\n",
    "\n",
    "                if args.h_flip and random.randint(0,1):\n",
    "                    input_image = cv2.flip(input_image, 1)\n",
    "                    output_image = cv2.flip(output_image, 1)\n",
    "                    if args.is_edge_weight:\n",
    "                        pixel_weight = cv2.flip(pixel_weight, 1)\n",
    "                if args.v_flip and random.randint(0,1):\n",
    "                    input_image = cv2.flip(input_image, 0)\n",
    "                    output_image = cv2.flip(output_image, 0)\n",
    "                    if args.is_edge_weight:\n",
    "                        pixel_weight = cv2.flip(pixel_weight, 0)\n",
    "                if args.brightness:\n",
    "                    factor = 1.0 + abs(random.gauss(mu=0.0, sigma=args.brightness))\n",
    "                    if random.randint(0,1):\n",
    "                        factor = 1.0/factor\n",
    "                    table = np.array([((i / 255.0) ** factor) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n",
    "                    input_image = cv2.LUT(input_image, table)\n",
    "                if args.rotation:\n",
    "                    angle = args.rotation\n",
    "                else:\n",
    "                    angle = 0.0\n",
    "                if args.zoom:\n",
    "                    scale = args.zoom\n",
    "                else:\n",
    "                    scale = 1.0\n",
    "                if args.rotation or args.zoom:\n",
    "                    M = cv2.getRotationMatrix2D((input_image.shape[1]//2, input_image.shape[0]//2), angle, scale)\n",
    "                    input_image = cv2.warpAffine(input_image, M, (input_image.shape[1], input_image.shape[0]))\n",
    "                    output_image = cv2.warpAffine(output_image, M, (output_image.shape[1], output_image.shape[0]))\n",
    "                    if args.is_edge_weight:\n",
    "                        pixel_weight = cv2.warpAffine(pixel_weight, M, (pixel_weight.shape[1], pixel_weight.shape[0]))\n",
    "\n",
    "                # Prep the data. Make sure the labels are in one-hot format\n",
    "                input_image = np.float32(input_image) / 255.0\n",
    "                output_image = np.float32(helpers.one_hot_it(label=output_image, num_classes=num_classes))\n",
    "                input_image_batch.append(np.expand_dims(input_image, axis=0))\n",
    "                output_image_batch.append(np.expand_dims(output_image, axis=0))\n",
    "                if args.is_edge_weight:\n",
    "                    pixel_weight_batch.append(pixel_weight[np.newaxis,:,:])\n",
    "\n",
    "            if args.batch_size == 1:\n",
    "                input_image_batch = input_image_batch[0]\n",
    "                output_image_batch = output_image_batch[0]\n",
    "                if args.is_edge_weight:\n",
    "                    pixel_weight_batch = pixel_weight_batch[0]\n",
    "            else:\n",
    "                input_image_batch = np.squeeze(np.stack(input_image_batch, axis=1))\n",
    "                output_image_batch = np.squeeze(np.stack(output_image_batch, axis=1))\n",
    "                if args.is_edge_weight:\n",
    "                    pixel_weight_batch = np.squeeze(np.stack(pixel_weight_batch, axis=1))\n",
    "                    # pixel_weight_batch = np.expand_dims(pixel_weight_batch, axis=3)\n",
    "\n",
    "            # Do the training\n",
    "            if args.is_edge_weight:\n",
    "                inp_dict = feed_all_gpu(inp_dict, models, payload_per_gpu, input_image_batch, output_image_batch, pixel_weight_batch)\n",
    "            else:\n",
    "                inp_dict = feed_all_gpu(inp_dict, models, payload_per_gpu, input_image_batch, output_image_batch, None)\n",
    "            _, current = sess.run([apply_gradient_op, aver_loss_op], inp_dict)\n",
    "\n",
    "            current_losses.append(current)\n",
    "            cnt = cnt + args.batch_size\n",
    "            if cnt % 20 == 0:\n",
    "                string_print = \"Epoch = %d Count = %d Current = %.2f Time = %.2f\"%(epoch,cnt,current,time.time()-st)\n",
    "                utils.LOG(string_print)\n",
    "\n",
    "        mean_loss = np.mean(current_losses)\n",
    "        avg_loss_per_epoch.append(mean_loss)\n",
    "\n",
    "        string_print = \"Training loss: Epoch = %d Count = %d Epoch Loss = %.2f\"%(epoch,cnt,mean_loss)\n",
    "        utils.LOG(string_print)\n",
    "        f.writelines(str(mean_loss)+'\\n')\n",
    "        f.flush()\n",
    "\n",
    "        # Create directories if needed\n",
    "        if not os.path.isdir(\"checkpoints_#%d/%04d\"%(args.exp_id, epoch)):\n",
    "            os.makedirs(\"checkpoints_#%d/%04d\"%(args.exp_id,epoch))\n",
    "\n",
    "        saver.save(sess,model_checkpoint_name)\n",
    "        saver.save(sess,\"checkpoints_#%d/%04d/model.ckpt\"%(args.exp_id,epoch))\n",
    "\n",
    "\n",
    "        target=open(\"checkpoints_#%d/%04d/val_scores.txt\"%(args.exp_id,epoch),'w')\n",
    "        target.write(\"val_name, avg_accuracy, precision, recall, f1 score, mean iou %s\\n\" % (class_names_string))\n",
    "\n",
    "        scores_list = []\n",
    "        class_scores_list = []\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        iou_list = []\n",
    "\n",
    "        # Do the validation on a small set of validation images\n",
    "        total_batch = int(len(val_indices) / args.batch_size)\n",
    "        val_payload_per_gpu = args.batch_size / len(gpu_ids)\n",
    "        for i in range(total_batch):\n",
    "            input_image_batch = []\n",
    "            output_image_batch = []\n",
    "            preds = None\n",
    "            # Collect a batch of images\n",
    "            for j in range(args.batch_size):\n",
    "                ind = i*args.batch_size+j\n",
    "                input_image = cv2.cvtColor(cv2.imread(val_input_names[ind],-1), cv2.COLOR_BGR2RGB)[:args.crop_height, :args.crop_width]/255.0\n",
    "                input_image_batch.append(np.expand_dims(input_image, axis=0))\n",
    "                output_image = cv2.imread(val_output_names[ind],-1)[:args.crop_height, :args.crop_width]\n",
    "                output_image = np.float32(helpers.one_hot_it(label=output_image, num_classes=num_classes))\n",
    "                output_image_batch.append(np.expand_dims(output_image, axis=0))\n",
    "            if args.batch_size == 1:\n",
    "                input_image_batch = input_image_batch[0]\n",
    "                output_image_batch = output_image_batch[0]\n",
    "            else:\n",
    "                input_image_batch = np.squeeze(np.stack(input_image_batch, axis=1))\n",
    "                output_image_batch = np.squeeze(np.stack(output_image_batch, axis=1))\n",
    "            inp_dict = feed_all_gpu({}, models, val_payload_per_gpu, input_image_batch, output_image_batch, None)\n",
    "            batch_pred = sess.run([all_pred], inp_dict)\n",
    "            # if preds is None:\n",
    "            preds = batch_pred\n",
    "            preds = np.stack(preds).reshape((args.batch_size,args.crop_width, args.crop_height,num_classes))\n",
    "            # print('preds.shape:',preds.shape)\n",
    "            for j in range(args.batch_size):\n",
    "                gt = output_image_batch[j,:,:,:]\n",
    "                output_image = preds[j,:,:,:] #np.squeeze(preds[j])\n",
    "                output_image = helpers.reverse_one_hot(output_image)\n",
    "                gt = helpers.reverse_one_hot(gt)\n",
    "                out_vis_image = helpers.colour_code_segmentation(output_image)\n",
    "\n",
    "                accuracy = utils.compute_avg_accuracy(output_image, gt)\n",
    "                class_accuracies = utils.compute_class_accuracies(output_image, gt, num_classes)\n",
    "                prec = utils.precision(output_image, gt)\n",
    "                rec = utils.recall(output_image, gt)\n",
    "                f1 = utils.f1score(output_image, gt)\n",
    "                iou = utils.compute_mean_iou(output_image, gt)\n",
    "            \n",
    "                file_name = utils.filepath_to_name(val_input_names[ind])\n",
    "                target.write(\"%s, %f, %f, %f, %f, %f\"%(file_name, accuracy, prec, rec, f1, iou))\n",
    "                for item in class_accuracies:\n",
    "                    target.write(\", %f\"%(item))\n",
    "                target.write(\"\\n\")\n",
    "\n",
    "                scores_list.append(accuracy)\n",
    "                class_scores_list.append(class_accuracies)\n",
    "                precision_list.append(prec)\n",
    "                recall_list.append(rec)\n",
    "                f1_list.append(f1)\n",
    "                iou_list.append(iou)\n",
    "                \n",
    "                gt = helpers.reverse_one_hot(helpers.one_hot_it(gt))\n",
    "                gt = helpers.colour_code_segmentation(gt)\n",
    "     \n",
    "                file_name = os.path.basename(val_input_names[ind])\n",
    "                file_name = os.path.splitext(file_name)[0]\n",
    "                cv2.imwrite(\"checkpoints_#%d/%04d/%s_pred.png\"%(args.exp_id,epoch, file_name),np.uint8(out_vis_image))\n",
    "                cv2.imwrite(\"checkpoints_#%d/%04d/%s_gt.png\"%(args.exp_id,epoch, file_name),np.uint8(gt))\n",
    "\n",
    "        target.close()\n",
    "\n",
    "        avg_score = np.mean(scores_list)\n",
    "        class_avg_scores = np.mean(class_scores_list, axis=0)\n",
    "        avg_scores_per_epoch.append(avg_score)\n",
    "        avg_precision = np.mean(precision_list)\n",
    "        avg_recall = np.mean(recall_list)\n",
    "        avg_f1 = np.mean(f1_list)\n",
    "        avg_iou = np.mean(iou_list)\n",
    "\n",
    "        print(\"\\nAverage validation accuracy for epoch # %04d = %f\"% (epoch, avg_score))\n",
    "        print(\"Average per class validation accuracies for epoch # %04d:\"% (epoch))\n",
    "        for index, item in enumerate(class_avg_scores):\n",
    "            print(\"%s = %f\" % (class_names_list[index], item))\n",
    "        print(\"Validation precision = \", avg_precision)\n",
    "        print(\"Validation recall = \", avg_recall)\n",
    "        print(\"Validation F1 score = \", avg_f1)\n",
    "        print(\"Validation IoU score = \", avg_iou)\n",
    "\n",
    "        scores_list = []\n",
    "\n",
    "    f.close()\n",
    "    fig = plt.figure(figsize=(11,8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    \n",
    "    ax1.plot(range(args.num_epochs), avg_scores_per_epoch)\n",
    "    ax1.set_title(\"Average validation accuracy vs epochs\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Avg. val. accuracy\")\n",
    "\n",
    "\n",
    "    plt.savefig('accuracy_vs_epochs_#%d.png' % args.exp_id)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    \n",
    "    ax1.plot(range(args.num_epochs), avg_loss_per_epoch)\n",
    "    ax1.set_title(\"Average loss vs epochs\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Current loss\")\n",
    "\n",
    "    plt.savefig('loss_vs_epochs_#%d.png' % args.exp_id)\n",
    "\n",
    "else:\n",
    "    print(\"***** Begin testing *****\")\n",
    "\n",
    "    # Create directories if needed\n",
    "    if not os.path.isdir(\"Test_#%d\"%(args.exp_id)):\n",
    "            os.makedirs(\"Test_#%d\"%(args.exp_id))\n",
    "\n",
    "    target=open(\"Test_#%d/test_scores.txt\"%(args.exp_id),'w')\n",
    "    target.write(\"test_name, avg_accuracy, precision, recall, f1 score, mean iou %s\\n\" % (class_names_string))\n",
    "    scores_list = []\n",
    "    class_scores_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    iou_list = []\n",
    "\n",
    "    # Run testing on ALL test images\n",
    "    for ind in range(len(test_input_names)):\n",
    "        sys.stdout.write(\"\\rRunning test image %d / %d\"%(ind+1, len(test_input_names)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        input_image = np.expand_dims(np.float32(cv2.cvtColor(cv2.imread(test_input_names[ind],-1), cv2.COLOR_BGR2RGB)[:args.crop_height, :args.crop_width]),axis=0)/255.0\n",
    "        st = time.time()\n",
    "        output_image = sess.run(network,feed_dict={input:input_image})\n",
    "        \n",
    "\n",
    "        gt = cv2.imread(test_output_names[ind],-1)[:args.crop_height, :args.crop_width]\n",
    "\n",
    "        output_image = np.array(output_image[0,:,:,:])\n",
    "        output_image = helpers.reverse_one_hot(output_image)\n",
    "        out_eval_image = output_image[:,:,0]\n",
    "        out_vis_image = helpers.colour_code_segmentation(output_image)\n",
    "\n",
    "        accuracy = utils.compute_avg_accuracy(out_eval_image, gt)\n",
    "        class_accuracies = utils.compute_class_accuracies(out_eval_image, gt)\n",
    "        prec = utils.precision(out_eval_image, gt)\n",
    "        rec = utils.recall(out_eval_image, gt)\n",
    "        f1 = utils.f1score(out_eval_image, gt)\n",
    "        iou = utils.compute_mean_iou(out_eval_image, gt)\n",
    "    \n",
    "        file_name = utils.filepath_to_name(test_input_names[ind])\n",
    "        target.write(\"%s, %f, %f, %f, %f, %f\"%(file_name, accuracy, prec, rec, f1, iou))\n",
    "        for item in class_accuracies:\n",
    "            target.write(\", %f\"%(item))\n",
    "        target.write(\"\\n\")\n",
    "\n",
    "        scores_list.append(accuracy)\n",
    "        class_scores_list.append(class_accuracies)\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_list.append(f1)\n",
    "        iou_list.append(iou)\n",
    "    \n",
    "        gt = helpers.reverse_one_hot(helpers.one_hot_it(gt))\n",
    "        gt = helpers.colour_code_segmentation(gt)\n",
    "\n",
    "        cv2.imwrite(\"Test_#%d/%s_pred.png\"%(args.exp_id, file_name),np.uint8(out_vis_image))\n",
    "        cv2.imwrite(\"Test_#%d/%s_gt.png\"%(args.exp_id, file_name),np.uint8(gt))\n",
    "\n",
    "\n",
    "    target.close()\n",
    "\n",
    "    avg_score = np.mean(scores_list)\n",
    "    class_avg_scores = np.mean(class_scores_list, axis=0)\n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    avg_f1 = np.mean(f1_list)\n",
    "    avg_iou = np.mean(iou_list)\n",
    "    print(\"Average test accuracy = \", avg_score)\n",
    "    print(\"Average per class test accuracies = \\n\")\n",
    "    for index, item in enumerate(class_avg_scores):\n",
    "        print(\"%s = %f\" % (class_names_list[index], item))\n",
    "    print(\"Average precision = \", avg_precision)\n",
    "    print(\"Average recall = \", avg_recall)\n",
    "    print(\"Average F1 score = \", avg_f1)\n",
    "    print(\"Average mean IoU score = \", avg_iou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
